{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0a36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c30b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Training.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f24e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I donâ€™t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>1370572921043701761</td>\n",
       "      <td>@galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen Iâ€™m ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1381076072129695746</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>1378912704530935809</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>1366144349940183042</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>1359849897068015620</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0     1382343793341575169  @IrvineWelsh I donâ€™t know about you Irvine but...   \n",
       "1     1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2     1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3     1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4     1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "...                   ...                                                ...   \n",
       "7595  1370572921043701761  @galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen Iâ€™m ...   \n",
       "7596  1381076072129695746  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597  1378912704530935809  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598  1366144349940183042  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599  1359849897068015620  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "7595      0  \n",
       "7596      1  \n",
       "7597      0  \n",
       "7598      0  \n",
       "7599      0  \n",
       "\n",
       "[7600 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04d5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define English stopwords\n",
    "english_stopwords = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "\n",
    "# Define function to preprocess text\n",
    "def preprocess_text(text):\n",
    "      \n",
    "    # Lowercasing\n",
    "    text = to_lowercase(text)\n",
    "    \n",
    "    text = text.replace(\"â€™\", \"'\") \n",
    "    \n",
    "    text = remove_contraction(text)\n",
    "    \n",
    "    text = convert_numbers_to_words(text)\n",
    "    \n",
    "    # Removing URLs\n",
    "    text = remove_urls(text)\n",
    "    \n",
    "    # Removing special characters\n",
    "    text = remove_special_characters(text)\n",
    "    \n",
    "    # Tokenization and removing stopwords\n",
    "    #tokens = text.split()\n",
    "    #tokens = [token for token in tokens if token not in english_stopwords]\n",
    "    \n",
    "    # Joining tokens\n",
    "    #text = ' '.join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_contraction(text):\n",
    "   # Define contractions\n",
    "    contractions = {\n",
    "        \"ain't\": \"am not / is not / are not / has not / have not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't've\": \"cannot have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he would / he had\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he will\",\n",
    "        \"he'll've\": \"he will have\",\n",
    "        \"he's\": \"he is / he has\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how is / how has / how does\",\n",
    "        \"i'd\": \"i would / I had\",\n",
    "        \"i'd've\": \"i would have\",\n",
    "        \"i'll\": \"i will\",\n",
    "        \"i'll've\": \"i will have\",\n",
    "        \"i'm\": \"i am\",\n",
    "        \"i've\": \"i have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it would / it had\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it will\",\n",
    "        \"it'll've\": \"it will have\",\n",
    "        \"it's\": \"it is / it has\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she would / she had\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she will\",\n",
    "        \"she'll've\": \"she will have\",\n",
    "        \"she's\": \"she is / she has\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so is / so has\",\n",
    "        \"that'd\": \"that would / that had\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that is / that has\",\n",
    "        \"there'd\": \"there would / there had\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there is / there has\",\n",
    "        \"they'd\": \"they would / they had\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they will\",\n",
    "        \"they'll've\": \"they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we would / we had\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what will\",\n",
    "        \"what'll've\": \"what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what is / what has\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when is / when has\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where is / where has\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who will\",\n",
    "        \"who'll've\": \"who will have\",\n",
    "        \"who's\": \"who is / who has\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why is / why has\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you would / you had\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you will\",\n",
    "        \"you'll've\": \"you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\"\n",
    "    }\n",
    "    # Expanding contractions\n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = text.replace(contraction, expansion)\n",
    "        \n",
    "    return text\n",
    "def convert_numbers_to_words(text):\n",
    "    # Define a dictionary mapping numeric words to their corresponding words\n",
    "    num_words = {\n",
    "        '0': 'zero',\n",
    "        '1': 'one',\n",
    "        '2': 'two',\n",
    "        '3': 'three',\n",
    "        '4': 'four',\n",
    "        '5': 'five',\n",
    "        '6': 'six',\n",
    "        '7': 'seven',\n",
    "        '8': 'eight',\n",
    "        '9': 'nine'\n",
    "    }\n",
    "     # Converting numbers to words\n",
    "    for digit, word in num_words.items():\n",
    "        text = text.replace(digit, word)\n",
    "    return text\n",
    "\n",
    "def to_lowercase(text):\n",
    "    lowercase_text = ''\n",
    "    for char in text:\n",
    "        # Check if character is uppercase\n",
    "        if 'A' <= char <= 'Z':\n",
    "            # Convert uppercase to lowercase\n",
    "            lowercase_text += chr(ord(char) + 32)\n",
    "        else:\n",
    "            lowercase_text += char\n",
    "    return lowercase_text\n",
    "\n",
    "\n",
    "# Function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # Define special characters\n",
    "    special_chars = {'!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~'}\n",
    "    return ''.join(char for char in text if char not in special_chars)\n",
    "\n",
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    # Filter out words that do not start with 'http' or 'https'\n",
    "    filtered_words = [word for word in words if not (word.startswith('http://') or word.startswith('https://'))]\n",
    "    # Join the filtered words back into a string\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbc705b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "#import demoji\n",
    "#demoji.download_codes()\n",
    "def emo(text):\n",
    "    temp=emoji.demojize(text,delimiters=(\" \",\" \"))\n",
    "    temp=temp.replace(\"_\",\"  \")\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1886511",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emo']=data[\"text\"].apply(lambda x:emo(x))\n",
    "data[\"clean_text\"]=data['emo'].apply(lambda X: preprocess_text(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c260289a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I donâ€™t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "      <td>@IrvineWelsh I donâ€™t know about you Irvine but...</td>\n",
       "      <td>irvinewelsh i do not know about you irvine but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>i bet money if i went n took a covid test righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>jamesmelville my wife received a positive covi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>out of the oneeightzerozerozerozero people who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>my whole family is sick af and here i am now i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382001700853125122</td>\n",
       "      <td>@renfrew1962 @PeakePolly @J_Deliciouso I'm not...</td>\n",
       "      <td>0</td>\n",
       "      <td>@renfrew1962 @PeakePolly @J  Deliciouso I'm no...</td>\n",
       "      <td>renfrewoneninesixtwo peakepolly j deliciouso i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383272654212272136</td>\n",
       "      <td>Test came back positive, no surprise. I have c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Test came back positive, no surprise. I have c...</td>\n",
       "      <td>test came back positive no surprise i have cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1374479299047084035</td>\n",
       "      <td>My Pawpaw has been in the hospital a few days....</td>\n",
       "      <td>0</td>\n",
       "      <td>My Pawpaw has been in the hospital a few days....</td>\n",
       "      <td>my pawpaw has been in the hospital a few days ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1354020426620547072</td>\n",
       "      <td>@MattHancock 4 people I know had covid and rec...</td>\n",
       "      <td>0</td>\n",
       "      <td>@MattHancock 4 people I know had covid and rec...</td>\n",
       "      <td>matthancock four people i know had covid and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1362671045136809985</td>\n",
       "      <td>Iâ€™m going to sound like I have lost my marbles...</td>\n",
       "      <td>1</td>\n",
       "      <td>Iâ€™m going to sound like I have lost my marbles...</td>\n",
       "      <td>i am going to sound like i have lost my marble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1373077971658022918</td>\n",
       "      <td>I just tested positive for Covid-19 from two s...</td>\n",
       "      <td>1</td>\n",
       "      <td>I just tested positive for Covid-19 from two s...</td>\n",
       "      <td>i just tested positive for covidonenine from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1373076070312730633</td>\n",
       "      <td>Someone I love very much was diagnosed with co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Someone I love very much was diagnosed with co...</td>\n",
       "      <td>someone i love very much was diagnosed with co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1331292744489250816</td>\n",
       "      <td>Dear @PeterHotez ,Serious question about Vacci...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dear @PeterHotez ,Serious question about Vacci...</td>\n",
       "      <td>dear peterhotez serious question about vaccine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1379116535726415874</td>\n",
       "      <td>As I was in the ER last night I overheard a co...</td>\n",
       "      <td>1</td>\n",
       "      <td>As I was in the ER last night I overheard a co...</td>\n",
       "      <td>as i was in the er last night i overheard a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1357823724192296960</td>\n",
       "      <td>@jrlsilverman @dilleradollar @OregonGovBrown ðŸ’¡...</td>\n",
       "      <td>0</td>\n",
       "      <td>@jrlsilverman @dilleradollar @OregonGovBrown  ...</td>\n",
       "      <td>jrlsilverman dilleradollar oregongovbrown ligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1376702269991890945</td>\n",
       "      <td>Today: 1 person (after overnight code) in ICU ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Today: 1 person (after overnight code) in ICU ...</td>\n",
       "      <td>today one person after overnight code in icu w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1377607714524831745</td>\n",
       "      <td>@Asilverlining20 @TVpsychologist @NHSuk Itâ€™s b...</td>\n",
       "      <td>0</td>\n",
       "      <td>@Asilverlining20 @TVpsychologist @NHSuk Itâ€™s b...</td>\n",
       "      <td>asilverliningtwozero tvpsychologist nhsuk it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1388377556097904640</td>\n",
       "      <td>These side effects are CRAZY!!! Got the second...</td>\n",
       "      <td>0</td>\n",
       "      <td>These side effects are CRAZY!!! Got the second...</td>\n",
       "      <td>these side effects are crazy got the second pf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1377509820425723912</td>\n",
       "      <td>@BethMooreLPM Continuing to #Pray for Healing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@BethMooreLPM Continuing to #Pray for Healing ...</td>\n",
       "      <td>bethmoorelpm continuing to pray for healing mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1383382420234280964</td>\n",
       "      <td>@mstranack @GillianMcKeith Just spoke to Hayde...</td>\n",
       "      <td>0</td>\n",
       "      <td>@mstranack @GillianMcKeith Just spoke to Hayde...</td>\n",
       "      <td>mstranack gillianmckeith just spoke to hayden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1333413081083310081</td>\n",
       "      <td>There are Lies, Damn lies, and Statistics.http...</td>\n",
       "      <td>0</td>\n",
       "      <td>There are Lies, Damn lies, and Statistics.http...</td>\n",
       "      <td>there are lies damn lies and statisticshttpstc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1386707720317935617</td>\n",
       "      <td>@basakcoruhUW @nickmmark I think what hurts th...</td>\n",
       "      <td>0</td>\n",
       "      <td>@basakcoruhUW @nickmmark I think what hurts th...</td>\n",
       "      <td>basakcoruhuw nickmmark i think what hurts the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1375292877195120640</td>\n",
       "      <td>@Tempid_ I actually tested positive for covid....</td>\n",
       "      <td>1</td>\n",
       "      <td>@Tempid   I actually tested positive for covid...</td>\n",
       "      <td>tempid i actually tested positive for covid wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1350649856830828546</td>\n",
       "      <td>@IA___09 @leighjoyus @lc5190 @FlatEarthCity It...</td>\n",
       "      <td>0</td>\n",
       "      <td>@IA      09 @leighjoyus @lc5190 @FlatEarthCity...</td>\n",
       "      <td>ia zeronine leighjoyus lcfiveoneninezero flate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1377254105752690696</td>\n",
       "      <td>A year ago, on this date, I made the decision ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A year ago, on this date, I made the decision ...</td>\n",
       "      <td>a year ago on this date i made the decision to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1383590378712956929</td>\n",
       "      <td>One week back from Daytona, my whole family ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>One week back from Daytona, my whole family ge...</td>\n",
       "      <td>one week back from daytona my whole family get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1388238564220030977</td>\n",
       "      <td>@TheDamaniFelder I still donâ€™t know anyone who...</td>\n",
       "      <td>0</td>\n",
       "      <td>@TheDamaniFelder I still donâ€™t know anyone who...</td>\n",
       "      <td>thedamanifelder i still do not know anyone who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1373218284129157120</td>\n",
       "      <td>@PointCrow Honestly just a text back from her ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@PointCrow Honestly just a text back from her ...</td>\n",
       "      <td>pointcrow honestly just a text back from her t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1385316180739624972</td>\n",
       "      <td>I have Covid. Yaay... ðŸ™„ðŸ™„ Went to get tested, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>I have Covid. Yaay...  face  with  rolling  ey...</td>\n",
       "      <td>i have covid yaay face with rolling eyes face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1386017989053624320</td>\n",
       "      <td>@AntiLockdownAl2 @Rainbowandsteel Totally ...s...</td>\n",
       "      <td>0</td>\n",
       "      <td>@AntiLockdownAl2 @Rainbowandsteel Totally ...s...</td>\n",
       "      <td>antilockdownaltwo rainbowandsteel totally some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                               text  \\\n",
       "0   1382343793341575169  @IrvineWelsh I donâ€™t know about you Irvine but...   \n",
       "1   1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2   1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3   1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4   1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "5   1382001700853125122  @renfrew1962 @PeakePolly @J_Deliciouso I'm not...   \n",
       "6   1383272654212272136  Test came back positive, no surprise. I have c...   \n",
       "7   1374479299047084035  My Pawpaw has been in the hospital a few days....   \n",
       "8   1354020426620547072  @MattHancock 4 people I know had covid and rec...   \n",
       "9   1362671045136809985  Iâ€™m going to sound like I have lost my marbles...   \n",
       "10  1373077971658022918  I just tested positive for Covid-19 from two s...   \n",
       "11  1373076070312730633  Someone I love very much was diagnosed with co...   \n",
       "12  1331292744489250816  Dear @PeterHotez ,Serious question about Vacci...   \n",
       "13  1379116535726415874  As I was in the ER last night I overheard a co...   \n",
       "14  1357823724192296960  @jrlsilverman @dilleradollar @OregonGovBrown ðŸ’¡...   \n",
       "15  1376702269991890945  Today: 1 person (after overnight code) in ICU ...   \n",
       "16  1377607714524831745  @Asilverlining20 @TVpsychologist @NHSuk Itâ€™s b...   \n",
       "17  1388377556097904640  These side effects are CRAZY!!! Got the second...   \n",
       "18  1377509820425723912  @BethMooreLPM Continuing to #Pray for Healing ...   \n",
       "19  1383382420234280964  @mstranack @GillianMcKeith Just spoke to Hayde...   \n",
       "20  1333413081083310081  There are Lies, Damn lies, and Statistics.http...   \n",
       "21  1386707720317935617  @basakcoruhUW @nickmmark I think what hurts th...   \n",
       "22  1375292877195120640  @Tempid_ I actually tested positive for covid....   \n",
       "23  1350649856830828546  @IA___09 @leighjoyus @lc5190 @FlatEarthCity It...   \n",
       "24  1377254105752690696  A year ago, on this date, I made the decision ...   \n",
       "25  1383590378712956929  One week back from Daytona, my whole family ge...   \n",
       "26  1388238564220030977  @TheDamaniFelder I still donâ€™t know anyone who...   \n",
       "27  1373218284129157120  @PointCrow Honestly just a text back from her ...   \n",
       "28  1385316180739624972  I have Covid. Yaay... ðŸ™„ðŸ™„ Went to get tested, b...   \n",
       "29  1386017989053624320  @AntiLockdownAl2 @Rainbowandsteel Totally ...s...   \n",
       "\n",
       "    label                                                emo  \\\n",
       "0       0  @IrvineWelsh I donâ€™t know about you Irvine but...   \n",
       "1       0  I bet money if i went n took a covid test righ...   \n",
       "2       0  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3       0  Out of the 180,000+ people who have had the tw...   \n",
       "4       0  My whole family is sick af and here I am now i...   \n",
       "5       0  @renfrew1962 @PeakePolly @J  Deliciouso I'm no...   \n",
       "6       1  Test came back positive, no surprise. I have c...   \n",
       "7       0  My Pawpaw has been in the hospital a few days....   \n",
       "8       0  @MattHancock 4 people I know had covid and rec...   \n",
       "9       1  Iâ€™m going to sound like I have lost my marbles...   \n",
       "10      1  I just tested positive for Covid-19 from two s...   \n",
       "11      0  Someone I love very much was diagnosed with co...   \n",
       "12      0  Dear @PeterHotez ,Serious question about Vacci...   \n",
       "13      1  As I was in the ER last night I overheard a co...   \n",
       "14      0  @jrlsilverman @dilleradollar @OregonGovBrown  ...   \n",
       "15      0  Today: 1 person (after overnight code) in ICU ...   \n",
       "16      0  @Asilverlining20 @TVpsychologist @NHSuk Itâ€™s b...   \n",
       "17      0  These side effects are CRAZY!!! Got the second...   \n",
       "18      0  @BethMooreLPM Continuing to #Pray for Healing ...   \n",
       "19      0  @mstranack @GillianMcKeith Just spoke to Hayde...   \n",
       "20      0  There are Lies, Damn lies, and Statistics.http...   \n",
       "21      0  @basakcoruhUW @nickmmark I think what hurts th...   \n",
       "22      1  @Tempid   I actually tested positive for covid...   \n",
       "23      0  @IA      09 @leighjoyus @lc5190 @FlatEarthCity...   \n",
       "24      0  A year ago, on this date, I made the decision ...   \n",
       "25      1  One week back from Daytona, my whole family ge...   \n",
       "26      0  @TheDamaniFelder I still donâ€™t know anyone who...   \n",
       "27      0  @PointCrow Honestly just a text back from her ...   \n",
       "28      0  I have Covid. Yaay...  face  with  rolling  ey...   \n",
       "29      0  @AntiLockdownAl2 @Rainbowandsteel Totally ...s...   \n",
       "\n",
       "                                           clean_text  \n",
       "0   irvinewelsh i do not know about you irvine but...  \n",
       "1   i bet money if i went n took a covid test righ...  \n",
       "2   jamesmelville my wife received a positive covi...  \n",
       "3   out of the oneeightzerozerozerozero people who...  \n",
       "4   my whole family is sick af and here i am now i...  \n",
       "5   renfrewoneninesixtwo peakepolly j deliciouso i...  \n",
       "6   test came back positive no surprise i have cov...  \n",
       "7   my pawpaw has been in the hospital a few days ...  \n",
       "8   matthancock four people i know had covid and r...  \n",
       "9   i am going to sound like i have lost my marble...  \n",
       "10  i just tested positive for covidonenine from t...  \n",
       "11  someone i love very much was diagnosed with co...  \n",
       "12  dear peterhotez serious question about vaccine...  \n",
       "13  as i was in the er last night i overheard a co...  \n",
       "14  jrlsilverman dilleradollar oregongovbrown ligh...  \n",
       "15  today one person after overnight code in icu w...  \n",
       "16  asilverliningtwozero tvpsychologist nhsuk it i...  \n",
       "17  these side effects are crazy got the second pf...  \n",
       "18  bethmoorelpm continuing to pray for healing mi...  \n",
       "19  mstranack gillianmckeith just spoke to hayden ...  \n",
       "20  there are lies damn lies and statisticshttpstc...  \n",
       "21  basakcoruhuw nickmmark i think what hurts the ...  \n",
       "22  tempid i actually tested positive for covid wa...  \n",
       "23  ia zeronine leighjoyus lcfiveoneninezero flate...  \n",
       "24  a year ago on this date i made the decision to...  \n",
       "25  one week back from daytona my whole family get...  \n",
       "26  thedamanifelder i still do not know anyone who...  \n",
       "27  pointcrow honestly just a text back from her t...  \n",
       "28  i have covid yaay face with rolling eyes face ...  \n",
       "29  antilockdownaltwo rainbowandsteel totally some...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f59aa263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am have not go do not\n"
     ]
    }
   ],
   "source": [
    "# Define contractions\n",
    "contractions = {\n",
    "    \"ain't\": \"am not / is not / are not / has not / have not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would / he had\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is / he has\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is / how has / how does\",\n",
    "    \"I'd\": \"I would / I had\",\n",
    "    \"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would / it had\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is / it has\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would / she had\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is / she has\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so is / so has\",\n",
    "    \"that'd\": \"that would / that had\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is / that has\",\n",
    "    \"there'd\": \"there would / there had\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is / there has\",\n",
    "    \"they'd\": \"they would / they had\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would / we had\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is / what has\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is / when has\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is / where has\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is / who has\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is / why has\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would / you had\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "text = \"I'm haven't go don't\"\n",
    "for contraction, expansion in contractions.items():\n",
    "    text = text.replace(contraction, expansion)\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eadd6221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emo</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382343793341575169</td>\n",
       "      <td>@IrvineWelsh I donâ€™t know about you Irvine but...</td>\n",
       "      <td>0</td>\n",
       "      <td>@IrvineWelsh I donâ€™t know about you Irvine but...</td>\n",
       "      <td>irvinewelsh donâ€™t know irvine keep told covid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377631738692796417</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>0</td>\n",
       "      <td>I bet money if i went n took a covid test righ...</td>\n",
       "      <td>bet money went n took covid test right imma te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1386448010029240326</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>0</td>\n",
       "      <td>@JamesMelville My wife received a POSITIVE Cov...</td>\n",
       "      <td>jamesmelville wife received positive covid tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361342676340211717</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>Out of the 180,000+ people who have had the tw...</td>\n",
       "      <td>oneeightzerozerozerozero people two vaccine sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386757983254765569</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>My whole family is sick af and here I am now i...</td>\n",
       "      <td>whole family sick af hospital heart palpitatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>1370572921043701761</td>\n",
       "      <td>@galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen Iâ€™m ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@galaflux @efb  1 @DrJekyllHJ7 @DrLeanaWen Iâ€™m...</td>\n",
       "      <td>galaflux efb one drjekyllhjseven drleanawen iâ€™...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1381076072129695746</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>@tabbattales @nursekelsey I ended up in the ho...</td>\n",
       "      <td>tabbattales nursekelsey ended hospital fever b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>1378912704530935809</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>0</td>\n",
       "      <td>@UNREALJUST @recDNA @CDCgov How do you know? M...</td>\n",
       "      <td>unrealjust recdna cdcgov know wife got market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>1366144349940183042</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>@angela14387 no it cant be that!  I wonder wha...</td>\n",
       "      <td>angelaonefourthreeeightseven cant wonder count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>1359849897068015620</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>Berwick-based clinical care assistant Fiona Ma...</td>\n",
       "      <td>berwickbased clinical care assistant fiona mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0     1382343793341575169  @IrvineWelsh I donâ€™t know about you Irvine but...   \n",
       "1     1377631738692796417  I bet money if i went n took a covid test righ...   \n",
       "2     1386448010029240326  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3     1361342676340211717  Out of the 180,000+ people who have had the tw...   \n",
       "4     1386757983254765569  My whole family is sick af and here I am now i...   \n",
       "...                   ...                                                ...   \n",
       "7595  1370572921043701761  @galaflux @efb_1 @DrJekyllHJ7 @DrLeanaWen Iâ€™m ...   \n",
       "7596  1381076072129695746  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597  1378912704530935809  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598  1366144349940183042  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599  1359849897068015620  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "      label                                                emo  \\\n",
       "0         0  @IrvineWelsh I donâ€™t know about you Irvine but...   \n",
       "1         0  I bet money if i went n took a covid test righ...   \n",
       "2         0  @JamesMelville My wife received a POSITIVE Cov...   \n",
       "3         0  Out of the 180,000+ people who have had the tw...   \n",
       "4         0  My whole family is sick af and here I am now i...   \n",
       "...     ...                                                ...   \n",
       "7595      0  @galaflux @efb  1 @DrJekyllHJ7 @DrLeanaWen Iâ€™m...   \n",
       "7596      1  @tabbattales @nursekelsey I ended up in the ho...   \n",
       "7597      0  @UNREALJUST @recDNA @CDCgov How do you know? M...   \n",
       "7598      0  @angela14387 no it cant be that!  I wonder wha...   \n",
       "7599      0  Berwick-based clinical care assistant Fiona Ma...   \n",
       "\n",
       "                                             clean_text  \n",
       "0     irvinewelsh donâ€™t know irvine keep told covid ...  \n",
       "1     bet money went n took covid test right imma te...  \n",
       "2     jamesmelville wife received positive covid tes...  \n",
       "3     oneeightzerozerozerozero people two vaccine sh...  \n",
       "4     whole family sick af hospital heart palpitatio...  \n",
       "...                                                 ...  \n",
       "7595  galaflux efb one drjekyllhjseven drleanawen iâ€™...  \n",
       "7596  tabbattales nursekelsey ended hospital fever b...  \n",
       "7597  unrealjust recdna cdcgov know wife got market ...  \n",
       "7598  angelaonefourthreeeightseven cant wonder count...  \n",
       "7599  berwickbased clinical care assistant fiona mat...  \n",
       "\n",
       "[7600 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecb52d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covidonenine has fdgfg\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary mapping numeric words to their corresponding words\n",
    "num_words = {\n",
    "    '0': 'zero',\n",
    "    '1': 'one',\n",
    "    '2': 'two',\n",
    "    '3': 'three',\n",
    "    '4': 'four',\n",
    "    '5': 'five',\n",
    "    '6': 'six',\n",
    "    '7': 'seven',\n",
    "    '8': 'eight',\n",
    "    '9': 'nine'\n",
    "}\n",
    "\n",
    "text = \"covid19 has fdgfg\"\n",
    " # Converting numbers to words\n",
    "for digit, word in num_words.items():\n",
    "    text = text.replace(digit, word)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cb1c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 24@ Welcome\n"
     ]
    }
   ],
   "source": [
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    # Filter out words that do not start with 'http' or 'https'\n",
    "    filtered_words = [word for word in words if not (word.startswith('http://') or word.startswith('https://'))]\n",
    "    # Join the filtered words back into a string\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "text = \"https://www.goggle.com i 24@ Welcome\"\n",
    "text = remove_urls(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c828c8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " not sure if I  do it.\n"
     ]
    }
   ],
   "source": [
    "contractions_map = {\n",
    "    \"I'm\": \"I am\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    # Add more contractions and their expansions as needed\n",
    "}\n",
    "def remove_contractions(text, contractions_map):\n",
    "    for contraction, expansion in contractions_map.items():\n",
    "        text = text.replace(contraction, \"\").replace(expansion, \"\")\n",
    "    return text\n",
    "\n",
    "# Example text containing contractions\n",
    "text_with_contractions = \"I'm not sure if I can't do it.\"\n",
    "\n",
    "# Remove contractions from the text\n",
    "cleaned_text = remove_contractions(text_with_contractions, contractions_map)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0af127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
